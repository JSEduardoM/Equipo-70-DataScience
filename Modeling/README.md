# ü§ñ Modelado Predictivo de Churn

## üéØ Objetivo

Entrenar, evaluar y comparar m√∫ltiples modelos de Machine Learning para predecir el churn de clientes, seleccionando el modelo con mejor desempe√±o para implementaci√≥n en producci√≥n.

---

## üìÅ Archivos en esta Carpeta

| Archivo | Descripci√≥n |
|---------|-------------|
| `modeling_pipeline.py` | Pipeline completo de entrenamiento y evaluaci√≥n |
| `feature_importance_rf.png` | Importancia de features del modelo Random Forest |
| `cm_random_forest.png` | Matriz de confusi√≥n - Random Forest |
| `cm_logistic_regression.png` | Matriz de confusi√≥n - Regresi√≥n Log√≠stica |
| `cm_decision_tree.png` | Matriz de confusi√≥n - √Årbol de Decisi√≥n |
| `cm_regresi√≥n_log√≠stica.png` | Matriz de confusi√≥n - Regresi√≥n Log√≠stica (espa√±ol) |
| `cm_√°rbol_de_decisi√≥n.png` | Matriz de confusi√≥n - √Årbol de Decisi√≥n (espa√±ol) |

---

## üöÄ C√≥mo Ejecutar

```bash
python Modeling/modeling_pipeline.py
```

**Tiempo de ejecuci√≥n**: ~30-60 segundos

---

## üìà Resultados Obtenidos

### 1. **Modelos Entrenados**

Se entrenaron y compararon **3 modelos de clasificaci√≥n**:

#### üìä Comparaci√≥n de Modelos

| Modelo | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|--------|----------|-----------|--------|----------|---------|
| **Regresi√≥n Log√≠stica** | 87.5% | 78.2% | 52.6% | 0.63 | 0.88 |
| **√Årbol de Decisi√≥n** | 92.9% | 85.7% | 68.1% | 0.76 | 0.87 |
| **Random Forest** ‚≠ê | **93.4%** | **88.8%** | **70.4%** | **0.78** | **0.97** |

---

### 2. **Modelo Seleccionado: Random Forest** ‚≠ê

#### ¬øPor qu√© Random Forest?

‚úÖ **Mayor Accuracy**: 93.4% - El m√°s alto de los tres modelos  
‚úÖ **Mejor ROC-AUC**: 0.97 - Excelente capacidad de discriminaci√≥n  
‚úÖ **Balance Precision-Recall**: 88.8% precision, 70.4% recall  
‚úÖ **Robusto**: Menos propenso a overfitting que √Årbol de Decisi√≥n  
‚úÖ **Interpretable**: Proporciona importancia de features  

#### M√©tricas Detalladas del Random Forest:

**Matriz de Confusi√≥n**:
```
                 Predicho: No Churn    Predicho: Churn
Real: No Churn         654                  19
Real: Churn             40                  95
```

**Interpretaci√≥n**:
- **True Negatives (TN)**: 654 - Clientes activos correctamente identificados
- **False Positives (FP)**: 19 - Clientes activos predichos como churn (error tipo I)
- **False Negatives (FN)**: 40 - Clientes churn predichos como activos (error tipo II)
- **True Positives (TP)**: 95 - Clientes churn correctamente identificados

**M√©tricas de Negocio**:
- **Precision (88.8%)**: De cada 100 clientes que predecimos har√°n churn, 89 realmente lo har√°n
- **Recall (70.4%)**: De cada 100 clientes que realmente har√°n churn, detectamos 70
- **Especificidad**: 97.2% - Muy bueno para identificar clientes que NO har√°n churn

---

### 3. **Top 10 Features M√°s Importantes**

![Feature Importance](feature_importance_rf.png)

| Ranking | Feature | Importancia | Interpretaci√≥n |
|---------|---------|-------------|----------------|
| 1 | **Antiguedad** | 25.9% | Tiempo del cliente en la plataforma |
| 2 | **Monto_Cashback** | 16.8% | Cantidad de recompensas recibidas |
| 3 | **Distancia_Almacen** | 10.3% | Distancia de entrega |
| 4 | **Numero_Direcciones** | 8.6% | Cantidad de direcciones registradas |
| 5 | **Dias_Ultima_Compra** | 8.1% | Tiempo desde √∫ltima compra |
| 6 | **Queja** | 7.4% | Si el cliente ha presentado quejas |
| 7 | **Nivel_Satisfaccion** | 6.9% | Puntuaci√≥n de satisfacci√≥n |
| 8 | **Numero_Dispositivos** | 5.8% | Dispositivos registrados |
| 9 | **Categoria_Preferida** | 5.2% | Categor√≠a de producto favorita |
| 10 | **Estado_Civil** | 5.0% | Estado civil del cliente |

#### üîç Insights de Features:

**Top 3 Features (52.9% de importancia total)**:
1. **Antiguedad (25.9%)**:
   - ‚úÖ Clientes con m√°s tiempo son m√°s leales
   - ‚ö†Ô∏è Nuevos clientes (0-3 meses) tienen alto riesgo
   
2. **Monto_Cashback (16.8%)**:
   - ‚úÖ Programa de recompensas es efectivo
   - üí° Aumentar cashback puede reducir churn
   
3. **Distancia_Almacen (10.3%)**:
   - ‚ö†Ô∏è Entregas lejanas aumentan probabilidad de churn
   - üí° Optimizar log√≠stica en zonas alejadas

---

### 4. **An√°lisis de Errores**

#### False Negatives (40 casos):
- **Impacto**: Clientes que har√°n churn pero no los detectamos
- **Costo**: P√©rdida de oportunidad de retenci√≥n
- **Mitigaci√≥n**: Monitoreo continuo de clientes en riesgo medio

#### False Positives (19 casos):
- **Impacto**: Clientes activos que marcamos como riesgo
- **Costo**: Recursos gastados en retenci√≥n innecesaria
- **Beneficio**: Mejor prevenir que lamentar - reforzar lealtad

---

### 5. **Comparaci√≥n con Otros Modelos**

#### Regresi√≥n Log√≠stica (Baseline):
- ‚úÖ **Ventajas**: Simple, r√°pido, interpretable
- ‚ùå **Desventajas**: Menor accuracy (87.5%), recall bajo (52.6%)
- üìä **Uso**: Bueno como baseline, pero insuficiente para producci√≥n

#### √Årbol de Decisi√≥n:
- ‚úÖ **Ventajas**: Muy interpretable, buen accuracy (92.9%)
- ‚ùå **Desventajas**: ROC-AUC menor (0.87), propenso a overfitting
- üìä **Uso**: Bueno para explicar decisiones, pero Random Forest es superior

---

## üìä Outputs Generados

### 1. **Visualizaciones**:
- `feature_importance_rf.png` - Importancia de variables
- `cm_random_forest.png` - Matriz de confusi√≥n del modelo final
- `cm_logistic_regression.png` - Matriz de confusi√≥n regresi√≥n log√≠stica
- `cm_decision_tree.png` - Matriz de confusi√≥n √°rbol de decisi√≥n

### 2. **Modelo Entrenado**:
- Modelo Random Forest guardado en memoria
- Listo para generar predicciones en el paso de Segmentaci√≥n

### 3. **M√©tricas de Evaluaci√≥n**:
- Accuracy, Precision, Recall, F1-Score para cada modelo
- ROC-AUC scores
- Matrices de confusi√≥n

---

## üéØ Interpretaci√≥n de Negocio

### 1. **Capacidad Predictiva**
- El modelo puede identificar **70.4% de los clientes que har√°n churn**
- De cada 100 predicciones de churn, **89 son correctas**
- Excelente para campa√±as de retenci√≥n dirigidas

### 2. **Factores Clave de Retenci√≥n**
Basado en feature importance:
1. **Onboarding**: Cr√≠tico en los primeros 3 meses
2. **Recompensas**: Programa de cashback es efectivo
3. **Log√≠stica**: Optimizar entregas en zonas alejadas
4. **Satisfacci√≥n**: Resolver quejas r√°pidamente

### 3. **ROI de Retenci√≥n**
- **Costo de retenci√≥n**: Menor que costo de adquisici√≥n
- **Precisi√≥n del modelo**: 88.8% reduce desperdicio de recursos
- **Cobertura**: 70.4% recall captura la mayor√≠a de churners

---

## üîó Relaci√≥n con Otras Etapas

### ‚¨ÖÔ∏è Entrada:
- `datos/dataset_ecommerce_limpio_es.csv` (del paso EDA)

### ‚û°Ô∏è Salida:
- Modelo Random Forest entrenado
- Features importantes identificadas
- M√©tricas de evaluaci√≥n
- Input para segmentaci√≥n de riesgo

---

## üìù Pr√≥ximos Pasos

‚úÖ **Completado**: Entrenamiento y evaluaci√≥n de modelos  
‚û°Ô∏è **Siguiente**: Segmentaci√≥n de clientes por riesgo (`Segmentation/`)

---

## üõ†Ô∏è Dependencias

```bash
pip install pandas numpy scikit-learn matplotlib seaborn
```

---

## üîß Configuraci√≥n del Modelo

```python
# Random Forest Configuration
n_estimators = 100
max_depth = None
min_samples_split = 2
min_samples_leaf = 1
random_state = 42
```

---

## üë§ Autor

**Equipo 70 - Data Science**  
No Country - Simulaci√≥n S11-25
